---
title: July 2
date: 2024-07-02
cover: https://oss.justin3go.com/blogs/fav0-001.jpg
---

Spend 1 minute every day to get the latest AI information.

The content includes but is not limited to **cutting-edge AI news**, **AI tools**, **AI painting**, **open-source projects**, and **learning tutorials**.

The main feature of the brief is its concise description, but important information is still introduced in detail through independent posts.

Here is the latest AI information for July 2.

### Cutting-edge Technology

**1. Runway has opened Gen3 for use!**

Currently, it only supports text-to-video generation, available for paid users. The effects are comparable to Luma and Kelan, each with its own pros and cons.

Runway is mainly too expensive, costing $1 per 5-second video. Kelan is still more attractive.

Official website: https://runwayml.com/

However, today a user achieved character consistency with Gen3, maintaining the same character across multiple generations.

![image-20240702231349788](https://p.ipic.vip/srnveb.png)

**2. Microsoft quietly updated Phi3-mini.**

The model's capabilities have been improved in various aspects, such as instruction-following ability and coding ability.

Model download: https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

![image-20240702231845162](https://p.ipic.vip/icyrc8.png)

### Cutting-edge Technology

**1. Tencent open-sourced a video generation project with specified actions: MinmicMotion.**

Similar to Alibaba's AnimateAnyone, it generates action videos of characters based on specified actions and character images.

The effects seem much better than Alibaba's, with consistent facial features and lip-syncing. It can be used not only for dance videos but also for digital humans.

Project introduction: https://tencent.github.io/MimicMotion/

GitHub: https://github.com/tencent/MimicMotion

Unofficial ComfyUI workflow: https://github.com/AIFSH/ComfyUI-MimicMotion

![model architecture](https://github.com/Tencent/MimicMotion/raw/main/assets/figures/model_structure.png)

### AI Painting

**1. Someone spent 3 months creating a graphic novel entirely using SD.**

The author's production tutorial shared:

- The painting model is iComix;
- Mixing famous actors in the prompts to maintain facial consistency;
- ControlNet Reference model for clothing consistency;
- ControlNet OpenPose model to control character poses;
- Using Photoshop to handle dialogue bubbles.

Original post: https://www.reddit.com/r/StableDiffusion/comments/1dpo14t/i_finally_published_a_graphic_novel_made_100_with

![image-20240702005718821](https://p.ipic.vip/yyuyh1.png)

### Learning Tutorials

**1. A step-by-step guide to building an AI video generation model from scratch.**

Found a tutorial on GitHub where the author explains in detail how to use Python to build a text-to-video generation model from scratch.

It covers the entire process from understanding theoretical concepts to architecture coding, and finally achieving video generation from text prompts.

GitHub: https://github.com/FareedKhan-dev/AI-text-to-video-model-from-scratch

Worth checking out if interested.

![AI-text-to-video-model](https://p.ipic.vip/ulcyn5.gif)

### Open-source Projects

**1. WebDesignAgent: an agent that helps you build a series of websites.**

Supports converting text descriptions, images, and visual cues into fully functional, beautifully designed websites, simplifying the website creation process with AI.

Detailed introduction: https://t.zsxq.com/3EIE3

![img](https://raw.githubusercontent.com/DAMO-NLP-SG/WebDesignAgent/main/assets/gui.png)
