---
title: December 07
date: 2024-12-07
cover: https://oss.justin3go.com/blogs/fav0-001.jpg
---

Today's featured cutting-edge AI news, welcome to read üëá

**üí° OpenAI launches reinforcement fine-tuning feature, requiring only a small amount of data to create domain expert AI, currently in closed beta for institutions only, expected to officially release in early 2025.**

**ü§ñ X (Twitter) platform's Grok AI is now available to all users, free users can ask 10 questions every 2 hours, Premium members get more usage.**

**üöÄ Meta open-sources Llama 3.3 70B model, performance rivals 405B parameter large models, surpassing Gemini 1.5 Pro and GPT-4 in multiple tests.**

**‚ö°Ô∏è Google quietly launches Gemini-exp-1206 experimental model, featuring 200 million context length, improved coding capabilities, available for free use in AI Studio.**

**üëÅÔ∏è Google open-sources PaliGemma 2 vision model, offering multiple sizes, excelling at generating detailed image descriptions, performing exceptionally in multiple professional domains.**



### Latest News

**1. OpenAI Day 2/12**

Launched reinforcement fine-tuning feature, requiring only a small amount of training data in specific domains to create domain expert AI models.

During today's livestream, OpenAI researchers demonstrated that after reinforcement fine-tuning the o1 mini model, its reasoning capabilities in specific domains significantly improved, even surpassing the official o1 model.

Official introduction: https://openai.com/form/rft-research-program/

Currently, this feature is only open for beta testing applications from research institutions, universities, and enterprises, with plans for official launch in early 2025.

![image-20241207102603357](https://cdn.jsdelivr.net/gh/freelander/oss@master/ai-daily/2024-12-07/image-20241207102603357.png)



**2. Grok AI is now available to all users.**

Starting yesterday, you can use Grok AI on X (Twitter) without requiring a subscription.

Access link: https://x.com/i/grok

However, there are question limits: 10 questions every 2 hours. To get more usage, you'll need to subscribe to Premium membership.

![image-20241207110513324](https://cdn.jsdelivr.net/gh/freelander/oss@master/ai-daily/2024-12-07/image-20241207110513324.png)

**3. Meta open-sources new Llama 3.3 70B model.**

Achieves performance levels comparable to Llama's largest 3.1 405B model, surpassing Gemini 1.5 Pro and GPT-4o in multiple benchmark tests.

Model download: https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct

![image-20241207111312231](https://cdn.jsdelivr.net/gh/freelander/oss@master/ai-daily/2024-12-07/image-20241207111312231.png)

**4. Google quietly releases new experimental model Gemini-exp-1206.**

Features 200 million context length, improved model coding capabilities, currently available for free use on Google AI Studio and Gemini API.

Try it online: https://aistudio.google.com

Official release came without detailed introduction, directly launched, reclaiming the top spot in the arena rankings. Worth trying out.

![image-20241207202824102](https://cdn.jsdelivr.net/gh/freelander/oss@master/ai-daily/2024-12-07/image-20241207202824102.png)



**5. Google open-sources powerful vision model PaliGemma 2.**

Offers multiple model sizes with 3B, 10B, 28B parameters, showing stronger performance than PaliGemma, capable of generating detailed image descriptions, not just identifying objects but also describing actions, emotions, and overall scene narratives.

Official introduction: https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/

Additionally, it shows excellent performance in chemical formula recognition, music notation recognition, chest X-ray reporting, and other domains.

![img](https://cdn.jsdelivr.net/gh/freelander/oss@master/ai-daily/2024-12-07/PaliGemma2__BlogHeader.original.png)